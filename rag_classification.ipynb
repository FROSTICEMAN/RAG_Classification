{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from transformers import GPT2TokenizerFast\n",
    "from typing import List\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models.azure_openai import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai_api_key = 'XXXX'  # Replace with your actual API key\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# Azure OpenAI deployment details\n",
    "openai_api_version = '2023-03-15-preview'\n",
    "deployment_name = 'XXXX'\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "# Classification model\n",
    "model_name = \"GPT-3.5\"  # Or 'GPT-4'\n",
    "\n",
    "# Define classification categories and their descriptions\n",
    "category_definitions = {\n",
    "    \"0\": \"Unrelated\",\n",
    "    \"1\": \"Insecticides\",\n",
    "    \"2\": \"Herbicides\",\n",
    "    \"3\": \"Fungicides\",\n",
    "}\n",
    "\n",
    "def text_word_splitter(text, num_words=2000):\n",
    "    \"\"\"Splits text into a maximum number of words.\"\"\"\n",
    "    text_list = text.split(\" \")\n",
    "    return \" \".join(text_list[:num_words])\n",
    "\n",
    "def classify_text(text, rag_model):\n",
    "    \"\"\"\n",
    "    Classifies a given text using the Azure LLM for text classification.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to classify.\n",
    "        rag_model (RetrievalQA): The retrieval-augmented generation model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the predicted category and justification.\n",
    "    \"\"\"\n",
    "    initial_prompt = f\"\"\"Act as a chemistry expert and assign one or several of the following categories (0, 1, 2, 3) to the patent text below. The categories are defined based on the following criteria:\n",
    "\n",
    "    ### Category Definitions\n",
    "    {category_definitions}\n",
    "\n",
    "    If the patent text is unrelated to any previous categories, assign category 0.\n",
    "    \"\"\"\n",
    "\n",
    "    template_string = initial_prompt + \"\"\"\n",
    "\n",
    "    ### Text:\n",
    "    {text}\n",
    "    ###\n",
    "\n",
    "    ### Output Format Instruction:\n",
    "    Output the results in the following JSON structure:\n",
    "    {{\"categories\": \"..\",\n",
    "     \"justification\": \"..\" }}\n",
    "\n",
    "    For the value 'categories' put all applicable categories separated with a semicolon.\n",
    "    For the value of \"justification\" put one short sentence regarding ALL defined categories above why it is assigned or not assigned. The structure should be category 0: one sentence for justification why it was assigned or not assigned; category 1: one sentence for justification why it was assigned or not assigned; ...\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template=template_string)\n",
    "    chat = AzureChatOpenAI(deployment_name=f\"XX-{model_name}-16k\")\n",
    "\n",
    "    messages = prompt.format_messages(text=text_word_splitter(text, num_words=2000))\n",
    "    response = chat(messages)\n",
    "\n",
    "    category_schema = ResponseSchema(name=\"categories\", description=\"Assigned categories\")\n",
    "    justification_schema = ResponseSchema(name=\"justification\", description=\"Justification for categories\")\n",
    "    response_schemas = [category_schema, justification_schema]\n",
    "\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    try:\n",
    "        output_dict = output_parser.parse(response.content)\n",
    "        return output_dict\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing LLM response: {e}\")\n",
    "        return {\"categories\": \"ERROR\", \"justification\": \"Error parsing response\"}\n",
    "\n",
    "# Load reference dataset and create embeddings\n",
    "reference_data_path = r\"path_to_reference_data.csv\"  # Path to reference data file\n",
    "loader = CSVLoader(file_path=reference_data_path)\n",
    "reference_docs = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=1)\n",
    "reference_texts = text_splitter.split_documents(reference_docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_base='XXXX',  # Replace with your actual OpenAI API base\n",
    "    openai_api_type='azure',\n",
    "    deployment='XXXX',  # Replace with your actual deployment name\n",
    "    openai_api_key=openai_api_key,\n",
    "    chunk_size=1,\n",
    ")\n",
    "doc_search = Chroma.from_documents(reference_texts, embeddings)\n",
    "\n",
    "rag_model = RetrievalQA(\n",
    "    retriever=doc_search.as_retriever(),\n",
    "    llm=AzureOpenAI(deployment_name=deployment_name)\n",
    ")\n",
    "\n",
    "# Path to the data file for classification and output path\n",
    "data_path = r\"path_to_data_for_classification.csv\"  # Adjust this path as needed\n",
    "output_path = r\"path_to_save_output_csv_file.csv\"  # Adjust this path as needed\n",
    "\n",
    "def classify_data(data_path, output_path, rag_model):\n",
    "    \"\"\"\n",
    "    Classifies text data from a CSV file and saves the results to another CSV file.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): The path to the CSV file containing text data.\n",
    "        output_path (str): The path to save the output CSV file with classifications.\n",
    "        rag_model (RetrievalQA): The retrieval-augmented generation model.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    classifications = []\n",
    "    for index, row in data.iterrows():\n",
    "        text = row['text_column_name']  # Replace 'text_column_name' with the actual name of the text column\n",
    "        classification_result = classify_text(text, rag_model)\n",
    "        classifications.append(classification_result)\n",
    "\n",
    "    classified_data = pd.DataFrame(classifications)\n",
    "    classified_data = pd.concat([data, classified_data], axis=1)\n",
    "    classified_data.to_csv(output_path, index=False)\n",
    "\n",
    "# Run the classification on the provided CSV file\n",
    "classify_data(data_path, output_path, rag_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from transformers import GPT2TokenizerFast\n",
    "from typing import List\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models.azure_openai import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai_api_key = 'XXXX'  # Replace with your actual API key\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# Azure OpenAI deployment details\n",
    "openai_api_version = '2023-03-15-preview'\n",
    "deployment_name = 'XXXX'\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "# Classification model\n",
    "model_name = \"GPT-3.5\"  # Or 'GPT-4'\n",
    "\n",
    "# Define classification categories and their descriptions\n",
    "category_definitions = {\n",
    "    \"0\": \"Unrelated\",\n",
    "    \"1\": \"Insecticides\",\n",
    "    \"2\": \"Herbicides\",\n",
    "    \"3\": \"Fungicides\",\n",
    "}\n",
    "\n",
    "def text_word_splitter(text, num_words=2000):\n",
    "    \"\"\"Splits text into a maximum number of words.\"\"\"\n",
    "    text_list = text.split(\" \")\n",
    "    return \" \".join(text_list[:num_words])\n",
    "\n",
    "def classify_text(text, rag_model):\n",
    "    \"\"\"\n",
    "    Classifies a given text using the Azure LLM for text classification.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to classify.\n",
    "        rag_model (RetrievalQA): The retrieval-augmented generation model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the predicted category and justification.\n",
    "    \"\"\"\n",
    "    initial_prompt = f\"\"\"Act as a chemistry expert and assign one or several of the following categories (0, 1, 2, 3) to the patent text below. The categories are defined based on the following criteria:\n",
    "\n",
    "    ### Category Definitions\n",
    "    {category_definitions}\n",
    "\n",
    "    If the patent text is unrelated to any previous categories, assign category 0.\n",
    "    \"\"\"\n",
    "\n",
    "    template_string = initial_prompt + \"\"\"\n",
    "\n",
    "    ### Text:\n",
    "    {text}\n",
    "    ###\n",
    "\n",
    "    ### Output Format Instruction:\n",
    "    Output the results in the following JSON structure:\n",
    "    {{\"categories\": \"..\",\n",
    "     \"justification\": \"..\" }}\n",
    "\n",
    "    For the value 'categories' put all applicable categories separated with a semicolon.\n",
    "    For the value of \"justification\" put one short sentence regarding ALL defined categories above why it is assigned or not assigned. The structure should be category 0: one sentence for justification why it was assigned or not assigned; category 1: one sentence for justification why it was assigned or not assigned; ...\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template=template_string)\n",
    "    chat = AzureChatOpenAI(deployment_name=f\"XX-{model_name}-16k\")\n",
    "\n",
    "    messages = prompt.format_messages(text=text_word_splitter(text, num_words=2000))\n",
    "    response = chat(messages)\n",
    "\n",
    "    category_schema = ResponseSchema(name=\"categories\", description=\"Assigned categories\")\n",
    "    justification_schema = ResponseSchema(name=\"justification\", description=\"Justification for categories\")\n",
    "    response_schemas = [category_schema, justification_schema]\n",
    "\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    try:\n",
    "        output_dict = output_parser.parse(response.content)\n",
    "        return output_dict\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing LLM response: {e}\")\n",
    "        return {\"categories\": \"ERROR\", \"justification\": \"Error parsing response\"}\n",
    "\n",
    "# Load reference dataset and create embeddings\n",
    "reference_data_path = r\"path_to_reference_data.csv\"  # Path to reference data file\n",
    "loader = CSVLoader(file_path=reference_data_path)\n",
    "reference_docs = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=1)\n",
    "reference_texts = text_splitter.split_documents(reference_docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_base='XXXX',  # Replace with your actual OpenAI API base\n",
    "    openai_api_type='azure',\n",
    "    deployment='XXXX',  # Replace with your actual deployment name\n",
    "    openai_api_key=openai_api_key,\n",
    "    chunk_size=1,\n",
    ")\n",
    "doc_search = Chroma.from_documents(reference_texts, embeddings)\n",
    "\n",
    "rag_model = RetrievalQA(\n",
    "    retriever=doc_search.as_retriever(),\n",
    "    llm=AzureOpenAI(deployment_name=deployment_name)\n",
    ")\n",
    "\n",
    "# Path to the data file for classification and output path\n",
    "data_path = r\"path_to_data_for_classification.csv\"  # Adjust this path as needed\n",
    "output_path = r\"path_to_save_output_csv_file.csv\"  # Adjust this path as needed\n",
    "\n",
    "def classify_data(data_path, output_path, rag_model):\n",
    "    \"\"\"\n",
    "    Classifies text data from a CSV file and saves the results to another CSV file.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): The path to the CSV file containing text data.\n",
    "        output_path (str): The path to save the output CSV file with classifications.\n",
    "        rag_model (RetrievalQA): The retrieval-augmented generation model.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    category_list = []\n",
    "    justification_list = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        text = row['text_column_name']  # Replace 'text_column_name' with the actual name of the text column\n",
    "        classification_result = classify_text(text, rag_model)\n",
    "        category_list.append(classification_result['categories'])\n",
    "        justification_list.append(classification_result['justification'])\n",
    "\n",
    "    data['Category Predictions'] = category_list\n",
    "    data['Justification of Category Predictions'] = justification_list\n",
    "    data.to_csv(output_path, index=False)\n",
    "\n",
    "# Run the classification on the provided CSV file\n",
    "classify_data(data_path, output_path, rag_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Final code\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from transformers import GPT2TokenizerFast\n",
    "from typing import List\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models.azure_openai import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai_api_key = 'XXXX'  # Replace with your actual API key\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# Azure OpenAI deployment details\n",
    "openai_api_version = '2023-03-15-preview'\n",
    "deployment_name = 'XXXX'\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "# Classification model\n",
    "model_name = \"GPT-3.5\"  # Or 'GPT-4'\n",
    "\n",
    "# Define classification categories and their descriptions\n",
    "category_definitions = {\n",
    "    \"0\": \"Unrelated\",\n",
    "    \"1\": \"Insecticides\",\n",
    "    \"2\": \"Herbicides\",\n",
    "    \"3\": \"Fungicides\",\n",
    "}\n",
    "\n",
    "def text_word_splitter(text, num_words=2000):\n",
    "    \"\"\"Splits text into a maximum number of words.\"\"\"\n",
    "    text_list = text.split(\" \")\n",
    "    return \" \".join(text_list[:num_words])\n",
    "\n",
    "def classify_text(text, rag_model):\n",
    "    \"\"\"\n",
    "    Classifies a given text using the Azure LLM for text classification.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to classify.\n",
    "        rag_model (RetrievalQA): The retrieval-augmented generation model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the predicted category and justification.\n",
    "    \"\"\"\n",
    "    initial_prompt = f\"\"\"Act as a chemistry expert and assign one or several of the following categories (0, 1, 2, 3) to the patent text below. The categories are defined based on the following criteria:\n",
    "\n",
    "    ### Category Definitions\n",
    "    {category_definitions}\n",
    "\n",
    "    If the patent text is unrelated to any previous categories, assign category 0.\n",
    "    \"\"\"\n",
    "\n",
    "    template_string = initial_prompt + \"\"\"\n",
    "\n",
    "    ### Text:\n",
    "    {text}\n",
    "    ###\n",
    "\n",
    "    ### Output Format Instruction:\n",
    "    Output the results in the following JSON structure:\n",
    "    {{\"categories\": \"..\",\n",
    "     \"justification\": \"..\" }}\n",
    "\n",
    "    For the value 'categories' put all applicable categories separated with a semicolon.\n",
    "    For the value of \"justification\" put one short sentence regarding ALL defined categories above why it is assigned or not assigned. The structure should be category 0: one sentence for justification why it was assigned or not assigned; category 1: one sentence for justification why it was assigned or not assigned; ...\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template=template_string)\n",
    "    chat = AzureChatOpenAI(deployment_name=f\"XX-{model_name}-16k\")\n",
    "\n",
    "    text_chunks = text_word_splitter(text, num_words=2000)\n",
    "    messages = prompt.format_messages(text=text_chunks)\n",
    "    response = chat(messages)\n",
    "\n",
    "    category_schema = ResponseSchema(name=\"categories\", description=\"Assigned categories\")\n",
    "    justification_schema = ResponseSchema(name=\"justification\", description=\"Justification for categories\")\n",
    "    response_schemas = [category_schema, justification_schema]\n",
    "\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    try:\n",
    "        output_dict = output_parser.parse(response.content)\n",
    "        return output_dict\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing LLM response: {e}\")\n",
    "        return {\"categories\": \"ERROR\", \"justification\": \"Error parsing response\"}\n",
    "\n",
    "# Load reference dataset and create embeddings\n",
    "reference_data_path = r\"path_to_reference_data.csv\"  # Path to reference data file\n",
    "loader = CSVLoader(file_path=reference_data_path)\n",
    "reference_docs = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=1)\n",
    "reference_texts = text_splitter.split_documents(reference_docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_base='XXXX',  # Replace with your actual OpenAI API base\n",
    "    openai_api_type='azure',\n",
    "    deployment='XXXX',  # Replace with your actual deployment name\n",
    "    openai_api_key=openai_api_key,\n",
    "    chunk_size=1,\n",
    ")\n",
    "doc_search = Chroma.from_documents(reference_texts, embeddings)\n",
    "\n",
    "rag_model = RetrievalQA(\n",
    "    retriever=doc_search.as_retriever(),\n",
    "    llm=AzureOpenAI(deployment_name=deployment_name)\n",
    ")\n",
    "\n",
    "# Path to the data file for classification and output path\n",
    "data_path = r\"path_to_data_for_classification.csv\"  # Adjust this path as needed\n",
    "output_path = r\"path_to_save_output_csv_file.csv\"  # Adjust this path as needed\n",
    "\n",
    "def classify_data(data_path, output_path, rag_model):\n",
    "    \"\"\"\n",
    "    Classifies text data from a CSV file and saves the results to another CSV file.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): The path to the CSV file containing text data.\n",
    "        output_path (str): The path to save the output CSV file with classifications.\n",
    "        rag_model (RetrievalQA): The retrieval-augmented generation model.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    category_list = []\n",
    "    justification_list = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        text = row['text']  # Replace 'text' with the actual name of the text column in your CSV\n",
    "        classification_result = classify_text(text, rag_model)\n",
    "        category_list.append(classification_result['categories'])\n",
    "        justification_list.append(classification_result['justification'])\n",
    "\n",
    "    data['Category Predictions'] = category_list\n",
    "    data['Justification of Category Predictions'] = justification_list\n",
    "    data.to_csv(output_path, index=False)\n",
    "\n",
    "# Run the classification on the provided CSV file\n",
    "classify_data(data_path, output_path, rag_model)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
